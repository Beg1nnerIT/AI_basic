# -*- coding: utf-8 -*-
"""TASK2_ML_PROCESS_4_TASK(1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mUa35QPD4nuwWy5G9jvgyazC174ux7cg

imię nazwisko:   
numer indeksu:   

zadanie dodatkowe:
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.linear_model import RidgeClassifier
from sklearn.metrics import precision_score, accuracy_score, recall_score, confusion_matrix, classification_report, roc_auc_score

#from google.colab import files
#uploaded = files.upload()

df = pd.read_csv("TASK2_ML_PROCESS_4.csv")
df.head()

df.dtypes

df.shape

df.isna().sum()
df=df.dropna()

df=df.drop("response",axis=1)

df=pd.get_dummies(df)
X = df.drop("response_binary", axis=1)
y = df["response_binary"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29, random_state=1)

gb_classifier = GradientBoostingClassifier(random_state=42)
ridge_classifier = RidgeClassifier(random_state=42)

gb_classifier.fit(X_train, y_train)
ridge_classifier.fit(X_train, y_train)

gb_predictions = gb_classifier.predict(X_test)
ridge_predictions = ridge_classifier.predict(X_test)

gb_accuracy = accuracy_score(y_test, gb_predictions)
ridge_accuracy = accuracy_score(y_test, ridge_predictions)

print("Gradient Boosting Classifier Accuracy:", gb_accuracy)
print("Ridge Classifier Accuracy:", ridge_accuracy)

from sklearn.model_selection import GridSearchCV
param_grid_gb = {
    'n_estimators': [10, 50],
    'learning_rate': [0.01, 0.1],
    'max_depth': [3, 5]
}

param_grid_ridge = {
    'alpha': [0.01, 0.1],
    'solver': ['auto', 'svd', 'cholesky']
}
# Przeszukiwanie siatki dla Gradient Boosting Classifier
gb_grid_search = GridSearchCV(gb_classifier, param_grid_gb, scoring='accuracy', cv=5)
gb_grid_search.fit(X_train, y_train)
gb_best_params = gb_grid_search.best_params_
gb_best_estimator = gb_grid_search.best_estimator_

# Przeszukiwanie siatki dla Ridge Classifier
ridge_grid_search = GridSearchCV(ridge_classifier, param_grid_ridge, scoring='accuracy', cv=5)
ridge_grid_search.fit(X_train, y_train)
ridge_best_params = ridge_grid_search.best_params_
ridge_best_estimator = ridge_grid_search.best_estimator_

# Predykcje dla najlepszych estymatorów
gb_predictions = gb_best_estimator.predict(X_test)
ridge_predictions = ridge_best_estimator.predict(X_test)

# Wydajność najlepszych estymatorów
gb_accuracy = accuracy_score(y_test, gb_predictions)
ridge_accuracy = accuracy_score(y_test, ridge_predictions)

gb_precision = precision_score(y_test, gb_predictions)
ridge_precision = precision_score(y_test, ridge_predictions)

gb_recall = recall_score(y_test, gb_predictions)
ridge_recall = recall_score(y_test, ridge_predictions)

gb_conf_matrix = confusion_matrix(y_test, gb_predictions)
ridge_conf_matrix = confusion_matrix(y_test, ridge_predictions)

gb_classification_rep = classification_report(y_test, gb_predictions)
ridge_classification_rep = classification_report(y_test, ridge_predictions)

gb_roc_auc = roc_auc_score(y_test, gb_predictions)
ridge_roc_auc = roc_auc_score(y_test, ridge_predictions)

# Porównanie wyników
print("Gradient Boosting Classifier:")
print("Best Parameters:", gb_best_params)
print("Accuracy:", gb_accuracy)
print("Precision:", gb_precision)
print("Recall:", gb_recall)
print("Confusion Matrix:\n", gb_conf_matrix)
print("Classification Report:\n", gb_classification_rep)
print("ROC AUC Score:", gb_roc_auc)

print("\nRidge Classifier:")
print("Best Parameters:", ridge_best_params)
print("Accuracy:", ridge_accuracy)
print("Precision:", ridge_precision)
print("Recall:", ridge_recall)
print("Confusion Matrix:\n", ridge_conf_matrix)
print("Classification Report:\n", ridge_classification_rep)
print("ROC AUC Score:", ridge_roc_auc)